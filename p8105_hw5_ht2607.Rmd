---
title: "p8105_hw5_ht2607"
output: html_document
date: "2023-11-04"
---

### Setting Up 

```{r setup, include=FALSE}
library(tidyverse)
library(ggridges)
library(patchwork)

library(p8105.datasets)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

### Question 1

## Homicides in Baltimore

```{r}
baltimore_df = 
  read_csv("q1data/homicide-data.csv") |> 
  filter(city == "Baltimore") |> 
  mutate(
    resolved = as.numeric(disposition == "Closed by arrest"),
    victim_age = as.numeric(victim_age)
  ) |> 
  select(resolved, victim_age, victim_race, victim_sex)
```


fitting a logistic regression

```{r}
fit_logistic = 
  baltimore_df |> 
  glm(
    resolved ~ victim_age + victim_race + victim_sex, 
    data = _, 
    family = binomial())
```

look at model results

```{r}
fit_logistic |> 
  broom::tidy() |> 
  mutate(OR = exp(estimate)) |> 
  select(term, estimate, OR)
```


```{r}
baltimore_df |> 
  count(victim_race)

```

### Question 2

Importing, combine, and cleaning the data
```{r}
library(purrr)
library(readr)

# Specify the directory where your CSV files are located
directory_path = "/Users/cindytseng/Desktop/p8105_hw5_ht2607/data/"

# List all CSV files
csv_files_df =
  list.files(directory_path, pattern = "\\.csv$", full.names = TRUE)

# Create a dataframe to store filenames
file_df = 
  tibble(
    files = list.files(directory_path),
    path = str_c(directory_path, files)
  ) |> 
  mutate(data = map(path, read_csv)) |> 
  unnest()

# Extract subject ID and arm from filenames
file_df <- file_df |> 
  mutate(
    subject_id = str_extract(files, "\\d+"), # Extract numerical subject ID
    arm = str_extract(files, "con|exp") # Extract arm information
  )

```

Tidy the dataframe
```{r}
# Unnest the data and select relevant columns
exp_con_tidy_df <- file_df |> 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    names_prefix = "week_",
    values_to = "values"
  ) |> 
  select(subject_id, arm, week, values) |>
  mutate(week = as.numeric(week))
  
```

Plotting the dataset 
```{r}
# Create a spaghetti plot showing observations on each subject over time
ggplot(exp_con_tidy_df, aes(x = week, y = values, color = subject_id)) + 
  facet_grid(. ~ arm) +
  geom_line() +
  labs(title = "Spaghetti Plot of Longitudinal Data",
       x = "Week",
       y = "Observation",
       color = "Arm") +
  theme(legend.position = "bottom")
```

From the graph we can see that in the experiment group have an upward trend among observation indicating that there might be an significant improvement of the condition in the experiment group compared to control group. In contrast, in the control group we can see there is irregular pattern among the observations. Especially, for arm 4, there is dramatically decrease trend of controling during week 6. 


### Question 3

Setting up the values based on the homework instruction
```{r}
library(tidyverse)

# setting up the values/ parameters according to the instruction 
n <- 30
sigma <- 5
alpha <- 0.05
mu_s <- c(0, 1, 2, 3, 4, 5, 6)

set.seed(1)

# creating a function and setting up 
sim_mean_sd = function(n = 30, mu, sigma = 5, alpha = 0.05) {
  
  sim_data = tibble(
    x = rnorm(n, mean = mu, sd = sigma),
  )
  
  sim_data |> 
    summarize(
      mu_hat = mean(x),
      sigma_hat = sd(x)
    )
}

```

Setting up the t-test for the later steps
```{r}
# creating a function for the t-test
t_test_function <- function(n, mu, sigma) {
  sample <- rnorm(n, mean = mu, sd = sigma)
  test_result <- t.test(sample, mu = 0)
  broom::tidy(test_result)
}
```

Setting up literation for the next step
```{r}
#create a dataframe to store the literation 
results <- tibble(mu = numeric(), mu_hat = numeric(), p_value = numeric(), reject = logical())
```

Begin literation 
```{r}
# doing literation for 5000 times (random sampling for 5000 times)
for (mu in mu_s) {
  for (i in 1:5000) {
    sim_results <- sim_mean_sd(n, mu, sigma)
    t_test_results <- t_test_function(n, mu, sigma)
    results <- results |> 
      add_row(mu = mu, 
              mu_hat = sim_results$mu_hat, 
              p_value = t_test_results$p.value, 
              reject = t_test_results$p.value < alpha)
  }
}
```

Computation the power 
```{r}
# calculating power
power_results <- results |> 
  group_by(mu) |> 
  summarise(power = mean(reject), 
            avg_mu_hat = mean(mu_hat), 
            avg_mu_hat_rejected = mean(mu_hat[reject]))
```

Plotting the first graph
```{r}
# Plotting power against true values of μ
power_plot <- power_results |> 
  ggplot(aes(x = mu, y = power)) +
  geom_point() +
  geom_line() +
  labs(title = "Power vs. True Value of μ",
       x = "True Value of μ",
       y = "Power")

# Display the plots
power_plot
```
From the plot we can see that as the true mean (effect size) increase, the power of the test (the probability that false null hypothesis is rejected) increase. This means, there is a positive association between the effect size and power. However, noted that when the value of power exceed to 1, we can see the line flatten. 

Plotting the second graph
```{r}
# Plotting average estimate of μ̂ against true values of μ
avg_estimate_plot <- results |> 
  group_by(mu) |> 
  summarise(avg_estimate = mean(mu_hat)) |> 
  ggplot(aes(x = mu, y = avg_estimate)) +
  geom_point() +
  geom_line() +
  labs(title = "Average Estimate of μ̂ vs. True Value of μ",
       x = "True Value of μ",
       y = "Average Estimate of μ̂")

# Display the plots
avg_estimate_plot

```

Plotting third graph based on plot 2
```{r}
# Overlaying average estimate of μ̂ for rejected null hypothesis
avg_estimate_rejected_plot <- results |> 
  filter(p_value < 0.05) |> 
  group_by(mu) |> 
  summarise(avg_estimate_rejected = mean(mu_hat)) |> 
  ggplot(aes(x = mu, y = avg_estimate_rejected)) +
  geom_point(color = "red") +
  geom_line(color = "red") +
  labs(title = "Average Estimate of μ̂ for Rejected Null Hypothesis vs. True Value of μ",
       x = "True Value of μ",
       y = "Average Estimate of μ̂")

# Display the plots
avg_estimate_rejected_plot
```
The graph illustrates that the mean of the sample (mû) in instances where the null hypothesis is rejected closely aligns with the true mean (μ), as evidenced by the convergence of lines for average estimates and conditional average estimates. This implies that, when the null hypothesis is rejected, the t-test serves as an unbiased estimator of the population mean, aligning with the expected characteristics of the t-test within the simulation.

